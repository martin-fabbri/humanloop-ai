{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89aef5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6a4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e2961a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the capital of France?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36dd0e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calcium CT score high cholesterol relationship',\n",
       " 'The user is asking about the relationship between Calcium CT score and high cholesterol, which requires a web search to provide an accurate answer about medical correlations and risk factors. ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(\n",
    "        None, description=\"Query that is optimized to search the web.\"\n",
    "    )\n",
    "    justification: str = Field(\n",
    "        None, description=\"Why this query is relevant to the user's request.\"\n",
    "    )\n",
    "\n",
    "structured_llm = llm.with_structured_output(SearchQuery)\n",
    "output = structured_llm.invoke(\n",
    "    \"How does Calcium CT score relate to high cholesterol?\"\n",
    ")\n",
    "output.search_query, output.justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c13f6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('multiply', {'a': 2.0, 'b': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"What is 2 times 3?\")\n",
    "\n",
    "msg.tool_calls[0][\"name\"], msg.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "465897fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    improved_joke: str\n",
    "    final_joke: str\n",
    "\n",
    "def generate_joke(state: State):\n",
    "    \"\"\"First LLM call to generate initial joke\"\"\"\n",
    "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "def check_pounchline(state: State):\n",
    "    \"\"\"Gate function to check if the joke has a punchline\"\"\"\n",
    "    if \"?\" in state[\"joke\"] or \"!\" in state[\"joke\"]:\n",
    "        return \"Pass\"\n",
    "    return \"Fail\"\n",
    "\n",
    "def improve_joke(state: State):\n",
    "    \"\"\"Second LLM call to improve the joke\"\"\"\n",
    "    msg = llm.invoke(\n",
    "        f\"Make this joke funnier by adding wordplay: {state['joke']}\"\n",
    "    )\n",
    "    return {\"improved_joke\": msg.content}\n",
    "\n",
    "def polish_joke(state: State):\n",
    "    \"\"\"Third LLM call to final Polish the joke\"\"\"\n",
    "    msg = llm.invoke(\n",
    "        f\"Add a surprising twist to this joke: {state['improved_joke']}\"\n",
    "    )\n",
    "    return {\"final_joke\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deac41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "workflow.add_node(\"improve_joke\", improve_joke)\n",
    "workflow.add_node(\"polish_joke\", polish_joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ae008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3786d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66165aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
